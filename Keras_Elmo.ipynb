{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Keras_Elmo.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"-lUTMFkW8ptt","colab_type":"code","outputId":"fca557fb-aadd-40cb-d800-9ef23c36c4c1","executionInfo":{"status":"ok","timestamp":1571626096193,"user_tz":-480,"elapsed":144293,"user":{"displayName":"Bryan Trac","photoUrl":"","userId":"17405550260864866588"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-yROzZgKATZA","colab_type":"code","outputId":"d4dec434-2e82-4f37-949f-1744d8a77ead","executionInfo":{"status":"ok","timestamp":1571626103561,"user_tz":-480,"elapsed":6699,"user":{"displayName":"Bryan Trac","photoUrl":"","userId":"17405550260864866588"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["!pip install keras==2.1.6"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting keras==2.1.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/e8/eaff7a09349ae9bd40d3ebaf028b49f5e2392c771f294910f75bb608b241/Keras-2.1.6-py2.py3-none-any.whl (339kB)\n","\u001b[K     |████████████████████████████████| 348kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.12.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (2.8.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.16.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.3.1)\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.2.5\n","    Uninstalling Keras-2.2.5:\n","      Successfully uninstalled Keras-2.2.5\n","Successfully installed keras-2.1.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RiuPY3icn81O","colab_type":"code","outputId":"cea95953-060b-4523-bddb-70b9506e9b82","executionInfo":{"status":"ok","timestamp":1571626138206,"user_tz":-480,"elapsed":12936,"user":{"displayName":"Bryan Trac","photoUrl":"","userId":"17405550260864866588"}},"colab":{"base_uri":"https://localhost:8080/","height":462}},"source":["#adapted from https://github.com/nxs5899/Named-Entity-Recognition_DeepLearning-keras\n","\n","from keras.models import Model, Input\n","from keras.layers.merge import add\n","from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from keras import backend as K\n","\n","tags = [\"I-Item\", \"B-Item\", \"I-Act\",\n","        \"B-Act\", \"I-Stat\", \"B-Stat\", \"O\"]\n","\n","max_len = 15\n","batch_size = 25\n","elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n","\n","def ElmoEmbedding(x):\n","    return elmo_model(inputs={\n","                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n","                            \"sequence_len\": tf.constant(batch_size*[max_len])\n","                      },\n","                      signature=\"tokens\",\n","                      as_dict=True)[\"elmo\"]\n","\n","\n","input_text = Input(shape=(max_len,), dtype=tf.string)\n","embed = Lambda(ElmoEmbedding, output_shape=(None, 1024))(input_text)\n","\n","x = LSTM(units=512, return_sequences=True,\n","                       recurrent_dropout=0.3, dropout=0.3)(embed)\n","x_rnn = LSTM(units=512, return_sequences=True,\n","                           recurrent_dropout=0.3, dropout=0.3)(x)\n","\n","x = add([x, x_rnn])  # residual connection to the first biLSTM\n","out = TimeDistributed(Dense(len(tags), activation=\"softmax\"))(x)\n","\n","model = Model(input_text, out)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:127: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:127: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3144: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3144: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"b65FccnX4VVT","colab_type":"code","outputId":"0875957a-d31e-4bc5-c9a6-3d92456959b4","executionInfo":{"status":"ok","timestamp":1571223920234,"user_tz":-480,"elapsed":3658403,"user":{"displayName":"Bryan Trac","photoUrl":"","userId":"17405550260864866588"}},"colab":{"base_uri":"https://localhost:8080/","height":734}},"source":["#adapted from https://github.com/nxs5899/Named-Entity-Recognition_DeepLearning-keras\n","\n","import numpy as np\n","import pandas as pd\n","import time\n","\n","start = time.time()\n","\n","file = 'drive/My Drive/Colab Notebooks/dat/train.txt'\n","separator = \"~\"\n","sentences = []\n","\n","\n","with open(file, 'r') as f:\n","    for num, line in enumerate(f):\n","        pairs = line.strip().split()\n","        sentence = []\n","        for pair in pairs:\n","            temp = pair.split(separator)\n","            temp.append(num)\n","            sentence.append(tuple(temp))\n","        sentences.append(sentence)\n","\n","\n","tag2idx = {t: i for i, t in enumerate(tags)}\n","\n","X = [[w[0] for w in s] for s in sentences]\n","\n","new_X = []\n","for seq in X:\n","    new_seq = []\n","    for i in range(max_len):\n","        try:\n","            new_seq.append(seq[i])\n","        except:\n","            new_seq.append(\"__PAD__\")\n","    new_X.append(new_seq)\n","X = new_X\n","\n","y = [[tag2idx[w[1]] for w in s] for s in sentences]\n","\n","from keras.preprocessing.sequence import pad_sequences\n","\n","y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.05, random_state=2019)\n","\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from keras import backend as K\n","\n","sess = tf.Session()\n","K.set_session(sess)\n","\n","\n","sess.run(tf.global_variables_initializer())\n","sess.run(tf.tables_initializer())\n","\n","\n","model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","\n","X_tr, X_val = X_tr[:1213*batch_size], X_tr[-135*batch_size:]\n","y_tr, y_val = y_tr[:1213*batch_size], y_tr[-135*batch_size:]\n","y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n","y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)\n","\n","history = model.fit(np.array(X_tr), y_tr, validation_data=(np.array(X_val), y_val),\n","                    batch_size=batch_size, epochs=3, verbose=1)\n","\n","hist = pd.DataFrame(history.history)\n","\n","model.save_weights(\"model-5k-3-epoch.h5\")\n","print(\"Saved model to disk\")\n","end = time.time()\n","print(end - start)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3040: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3040: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:977: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:977: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:964: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:964: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 3800 samples, validate on 3375 samples\n","Epoch 1/3\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:168: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:168: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:184: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:184: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:193: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:193: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:200: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:200: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["3775/3800 [============================>.] - ETA: 3s - loss: 0.2197 - acc: 0.9141"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I2DNCGW6A9eU","colab_type":"code","colab":{}},"source":["https://github.com/nxs5899/Named-Entity-Recognition_DeepLearning-keras\n","\n","file = 'drive/My Drive/Colab Notebooks/dat/ExpertTest.txt'\n","\n","separator = \"~\"\n","sentences = []\n","\n","\n","with open(file, 'r') as f:\n","    for num, line in enumerate(f):\n","        pairs = line.strip().split()\n","        sentence = []\n","        for pair in pairs:\n","            temp = pair.split(':')[-1].split(separator)\n","            temp.append(num)\n","            sentence.append(tuple(temp))\n","        sentences.append(sentence)\n","\n","\n","tag2idx = {t: i for i, t in enumerate(tags)}\n","\n","X = [[w[0] for w in s] for s in sentences]\n","\n","new_X = []\n","for seq in X:\n","    new_seq = []\n","    for i in range(max_len):\n","        try:\n","            new_seq.append(seq[i])\n","        except:\n","            new_seq.append(\"__PAD__\")\n","    new_X.append(new_seq)\n","X = new_X\n","\n","y = [[tag2idx[w[1]] for w in s] for s in sentences]\n","\n","from keras.preprocessing.sequence import pad_sequences\n","\n","y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_tmp, X_te, y_tmp, y_te = train_test_split(X, y, test_size=0.95, random_state=2019)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0iCkp32_Iet","colab_type":"code","outputId":"e95360fc-f243-4125-9fbd-df353e2b1401","executionInfo":{"status":"error","timestamp":1571225280166,"user_tz":-480,"elapsed":1187490,"user":{"displayName":"Bryan Trac","photoUrl":"","userId":"17405550260864866588"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy as np\n","import re\n","from keras.models import Model\n","from keras.preprocessing.sequence import pad_sequences\n","\n","option = 1\n","test_file = 'drive/My Drive/Colab Notebooks/dat/ExpertTest.txt'\n","\n","act = 0\n","item= 0\n","stat= 0\n","o=0\n","act_tag =0\n","item_tag=0\n","stat_tag=0\n","o_tag=0\n","act_count =0\n","item_count=0\n","stat_count=0\n","o_count=0\n","\n","p_txt = 'drive/My Drive/Colab Notebooks/dat/kerasPred.txt'\n","\n","with open(p_txt, 'w') as p_txt:\n","  if option == 1:\n","      accuracy = 0\n","      true_acc=0\n","      total = 0\n","      for i in range(len(X_te)):\n","          p = model.predict(np.array(X_te[i:i + batch_size]))[0]\n","          p = np.argmax(p, axis=-1)\n","          #print(\"{:15} {:5}: ({})\".format(\"Word\", \"Pred\", \"True\"))\n","          #print(\"=\" * 30)\n","          #print(i)\n","          if total != 0:\n","              #print(np.array(X_te[i:i + batch_size]))\n","              print(i, ' : ', accuracy / total * 100)\n","              print(act,item,stat,o)\n","              print(act_tag,item_tag,stat_tag,o_tag)\n","              print(act_count,item_count,stat_count,o_count)\n","          for w, true, pred in zip(X_te[i], y_te[i], p):\n","              if w != \"__PAD__\":\n","                  #keras.write(\"{:15}:{:5} ({})\".format(w, tags[pred], tags[true]))\n","                  if tags[true] == tags[pred]:\n","                      if tags[true].endswith('Act'):\n","                        act = act+1\n","                      elif tags[true].endswith('Item'):\n","                        item = item+1                    \n","                      elif tags[true].endswith('Stat'):\n","                        stat = stat+1\n","                      elif tags[true].endswith('O'):\n","                        o = o+1\n","\n","                      accuracy = accuracy + 1\n","                      tru_acc = true_acc + 1\n","\n","                      # else if tags match but BIO tags are wrong, increment by half\n","                  elif tags[true].split('-')[-1] == tags[pred].split('-')[-1]:\n","                      if tags[true].endswith('Act'):\n","                        act = act+1\n","                      elif tags[true].endswith('Item'):\n","                        item = item+1                    \n","                      elif tags[true].endswith('Stat'):\n","                        stat = stat+1\n","                      elif tags[true].endswith('O'):\n","                        o = o+1\n","                      accuracy = accuracy + 0.5\n","                      tru_acc = true_acc + 1\n","\n","                  total = total + 1\n","                  if tags[true].endswith('Act'):\n","                      act_count = act_count+1\n","                  elif tags[true].endswith('Item'):\n","                      item_count = item_count+1           \n","                  elif tags[true].endswith('Stat'):\n","                      stat_count = stat_count+1\n","                  elif tags[true].endswith('O'):\n","                      o_count = o_count+1\n","                      \n","                  if tags[pred].endswith('Act'):\n","                    act_tag = act_tag +1\n","                  elif tags[pred].endswith('Item'):\n","                    item_tag = item_tag +1\n","                  elif tags[pred].endswith('Stat'):\n","                    stat_tag = stat_tag +1\n","                  elif tags[pred].endswith('O'):\n","                    o_tag = o_tag +1\n","\n","  else:\n","      i = 19\n","      p = model.predict(np.array(X_te[i:i + batch_size]))[0]\n","      p = np.argmax(p, axis=-1)\n","      print(\"{:15} {:5}: ({})\".format(\"Word\", \"Pred\", \"True\"))\n","      print(\"=\" * 30)\n","      for w, true, pred in zip(X_te[i], y_te[i], p):\n","          if w != \"__PAD__\":\n","              print(\"{:15}:{:5} ({})\".format(w, tags[pred], tags[true]))\n","            \n","print('total: ', accuracy / total * 100)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1  :  0.0\n","0 0 0 0\n","0 2 0 3\n","0 1 4 0\n","2  :  21.428571428571427\n","0 2 0 0\n","0 4 0 3\n","0 3 4 0\n","3  :  27.77777777777778\n","1 2 0 0\n","1 4 0 4\n","1 4 4 0\n","4  :  46.42857142857143\n","2 3 0 2\n","2 6 0 6\n","2 5 5 2\n","5  :  44.73684210526316\n","2 3 0 4\n","3 8 0 8\n","2 5 5 7\n","6  :  47.72727272727273\n","3 4 0 4\n","4 9 0 9\n","3 7 5 7\n","7  :  48.0\n","4 5 0 4\n","6 10 0 9\n","4 9 5 7\n","8  :  51.724137931034484\n","4 7 1 4\n","6 12 1 10\n","4 12 6 7\n","9  :  54.285714285714285\n","5 9 2 4\n","7 14 2 12\n","5 14 9 7\n","10  :  58.97435897435898\n","6 11 2 5\n","8 16 2 13\n","6 16 9 8\n","11  :  57.77777777777777\n","6 11 2 8\n","9 16 2 18\n","7 17 9 12\n","12  :  59.61538461538461\n","7 12 2 11\n","11 17 2 22\n","8 19 9 16\n","13  :  57.89473684210527\n","7 12 2 13\n","12 19 2 24\n","8 19 9 21\n","14  :  60.0\n","8 14 2 13\n","13 21 2 24\n","9 21 9 21\n","15  :  61.53846153846154\n","9 14 2 16\n","14 22 2 27\n","10 21 9 25\n","16  :  62.5\n","10 14 2 20\n","15 24 2 31\n","11 21 9 31\n","17  :  67.07317073170732\n","10 14 2 30\n","15 24 2 41\n","11 21 9 41\n","18  :  67.05882352941175\n","11 14 3 30\n","16 24 3 42\n","12 22 10 41\n","19  :  65.0\n","11 15 3 31\n","16 25 3 46\n","13 25 10 42\n","20  :  65.42553191489363\n","11 17 4 31\n","16 27 4 47\n","13 28 11 42\n","21  :  65.15151515151516\n","12 17 4 33\n","17 29 4 49\n","14 28 11 46\n","22  :  64.42307692307693\n","12 19 4 34\n","17 32 4 51\n","14 31 11 48\n","23  :  65.13761467889908\n","12 19 4 38\n","17 32 4 56\n","15 31 11 52\n","24  :  65.17857142857143\n","13 19 4 39\n","18 33 4 57\n","16 31 11 54\n","25  :  65.51724137931035\n","13 19 4 42\n","18 34 4 60\n","16 31 11 58\n","26  :  65.54621848739495\n","13 19 4 44\n","18 35 4 62\n","17 31 11 60\n","27  :  66.39344262295081\n","14 21 4 44\n","19 37 4 62\n","18 33 11 60\n","28  :  67.2\n","14 23 5 44\n","19 39 5 62\n","18 35 12 60\n","29  :  66.27906976744185\n","14 24 5 45\n","19 41 5 64\n","19 37 12 61\n","30  :  66.54135338345864\n","14 25 5 47\n","19 42 5 67\n","19 38 13 63\n","31  :  65.35714285714286\n","15 25 5 49\n","21 43 5 71\n","20 38 17 65\n","32  :  65.625\n","15 26 7 49\n","21 44 7 72\n","20 40 19 65\n","33  :  65.87837837837837\n","16 28 7 49\n","22 46 7 73\n","21 43 19 65\n","34  :  65.66666666666666\n","16 28 7 50\n","22 47 7 74\n","21 43 19 67\n","35  :  65.9090909090909\n","16 30 8 50\n","22 50 8 74\n","22 45 20 67\n","36  :  65.72327044025157\n","16 31 8 52\n","22 51 8 78\n","22 48 20 69\n","37  :  66.56441717791411\n","16 31 8 56\n","22 51 8 82\n","22 48 20 73\n","38  :  66.36904761904762\n","17 32 8 57\n","23 53 8 84\n","23 50 21 74\n","39  :  66.37426900584795\n","18 32 8 58\n","24 54 8 85\n","24 50 21 76\n","40  :  66.57142857142857\n","19 32 8 60\n","25 54 8 88\n","25 51 21 78\n","41  :  66.38888888888889\n","20 34 8 60\n","26 56 8 90\n","26 55 21 78\n","42  :  66.39344262295081\n","21 35 8 60\n","27 57 8 91\n","27 57 21 78\n","43  :  65.86021505376344\n","21 36 8 60\n","27 59 8 92\n","27 58 23 78\n","44  :  66.58031088082902\n","22 36 8 65\n","28 60 8 97\n","28 58 23 84\n","45  :  66.41025641025641\n","23 36 8 65\n","29 60 8 98\n","29 59 23 84\n","46  :  66.24365482233503\n","24 36 8 65\n","30 60 8 99\n","30 60 23 84\n","47  :  66.42156862745098\n","25 37 9 67\n","31 61 9 103\n","31 63 24 86\n","48  :  66.02870813397129\n","25 38 9 69\n","31 63 9 106\n","32 65 24 88\n","49  :  65.87677725118483\n","26 38 9 69\n","32 63 9 107\n","33 66 24 88\n","50  :  65.72769953051643\n","26 39 9 69\n","32 65 9 107\n","33 67 25 88\n","51  :  65.27777777777779\n","26 39 9 70\n","32 67 9 108\n","34 67 25 90\n","52  :  65.13761467889908\n","26 39 10 70\n","32 67 10 109\n","34 68 26 90\n","53  :  65.31531531531532\n","26 40 12 70\n","32 68 12 110\n","34 70 28 90\n","54  :  64.75770925110133\n","26 40 12 72\n","32 70 12 113\n","34 70 31 92\n","55  :  64.65517241379311\n","26 40 12 75\n","32 70 12 118\n","34 72 31 95\n","56  :  64.1025641025641\n","26 40 12 75\n","32 71 12 119\n","35 73 31 95\n","57  :  64.28571428571429\n","26 40 12 78\n","32 72 12 122\n","35 73 31 99\n","58  :  63.37448559670782\n","26 40 13 78\n","32 72 13 126\n","35 74 35 99\n","59  :  64.82213438735178\n","26 40 13 88\n","32 72 13 136\n","35 74 35 109\n","60  :  64.98054474708171\n","27 42 13 88\n","33 74 13 137\n","36 76 36 109\n","61  :  65.38461538461539\n","28 44 13 88\n","34 76 13 137\n","37 78 36 109\n","62  :  64.82889733840305\n","28 45 13 88\n","34 78 13 138\n","38 80 36 109\n","63  :  64.71698113207547\n","29 45 13 88\n","35 78 13 139\n","39 81 36 109\n","64  :  64.76014760147602\n","29 45 13 92\n","36 78 13 144\n","39 83 36 113\n","65  :  64.74820143884892\n","30 46 13 95\n","38 79 13 148\n","40 86 36 116\n","66  :  64.66431095406361\n","30 48 13 96\n","38 82 13 150\n","41 89 36 117\n","67  :  64.33566433566433\n","30 48 13 97\n","38 83 13 152\n","41 89 38 118\n","68  :  64.38356164383562\n","32 49 13 98\n","40 84 13 155\n","44 91 38 119\n","69  :  64.1891891891892\n","33 50 13 98\n","41 85 13 157\n","45 94 38 119\n","70  :  64.42953020134227\n","34 51 13 98\n","42 86 13 157\n","46 95 38 119\n","71  :  64.56953642384106\n","34 52 14 99\n","42 87 14 159\n","46 97 39 120\n","72  :  64.80263157894737\n","35 52 14 100\n","43 87 14 160\n","47 97 39 121\n","73  :  65.16129032258064\n","36 52 14 104\n","44 87 14 165\n","48 97 40 125\n","74  :  65.39682539682539\n","37 54 14 105\n","45 89 14 167\n","49 100 40 126\n","75  :  65.9375\n","37 56 15 107\n","45 91 15 169\n","49 102 41 128\n","76  :  65.84615384615384\n","37 56 15 110\n","45 93 15 172\n","50 102 41 132\n","77  :  66.26139817629179\n","38 58 16 110\n","46 95 16 172\n","51 104 42 132\n","78  :  66.36636636636636\n","39 60 16 110\n","47 97 16 173\n","52 107 42 132\n","79  :  66.36904761904762\n","39 61 16 111\n","47 98 16 175\n","52 109 42 133\n","80  :  66.61764705882352\n","40 62 16 113\n","48 99 16 177\n","53 110 42 135\n","81  :  66.23188405797102\n","40 63 17 113\n","48 100 17 180\n","53 112 45 135\n","82  :  66.42857142857143\n","41 64 18 114\n","49 101 18 182\n","54 114 46 136\n","83  :  65.96045197740112\n","41 64 18 115\n","49 103 18 184\n","56 114 46 138\n","84  :  66.25\n","41 66 18 118\n","49 105 18 188\n","57 116 46 141\n","85  :  66.34615384615384\n","42 66 18 120\n","50 106 18 190\n","59 116 46 143\n","86  :  66.71195652173914\n","43 68 18 121\n","51 108 18 191\n","60 118 46 144\n","87  :  65.9090909090909\n","43 68 18 122\n","51 109 18 196\n","61 121 46 146\n","88  :  65.91511936339522\n","43 69 19 122\n","51 110 19 197\n","61 123 47 146\n","89  :  65.75520833333334\n","44 69 19 125\n","52 111 19 202\n","62 125 47 150\n","90  :  66.1082474226804\n","45 71 19 126\n","53 113 19 203\n","63 127 47 151\n","91  :  66.03053435114504\n","46 71 19 128\n","54 115 19 205\n","64 127 47 155\n","92  :  65.61712846347606\n","46 71 19 129\n","54 115 19 209\n","64 128 49 156\n","93  :  65.46134663341647\n","47 71 19 130\n","56 116 19 210\n","65 128 49 159\n","94  :  65.55555555555556\n","48 71 19 132\n","57 116 19 213\n","66 129 49 161\n","95  :  65.15892420537898\n","48 71 19 133\n","58 116 19 216\n","67 131 49 162\n","96  :  65.16990291262135\n","48 73 19 133\n","58 118 19 217\n","68 133 49 162\n","97  :  65.5048076923077\n","48 75 21 133\n","58 120 21 217\n","68 135 51 162\n","98  :  65.40284360189574\n","50 75 22 134\n","60 122 22 218\n","70 135 54 163\n","99  :  65.41176470588236\n","50 75 22 136\n","60 122 22 221\n","71 135 54 165\n","100  :  65.4292343387471\n","51 77 22 137\n","61 124 22 224\n","72 139 54 166\n","101  :  65.13761467889908\n","52 77 22 138\n","62 125 22 227\n","74 140 55 167\n","102  :  65.15837104072398\n","53 78 22 140\n","63 127 22 230\n","75 142 55 170\n","103  :  64.42953020134227\n","53 78 22 140\n","63 129 22 233\n","78 142 55 172\n","104  :  64.45916114790286\n","54 80 22 141\n","64 131 22 236\n","79 146 55 173\n","105  :  64.11378555798687\n","54 81 22 141\n","64 133 22 238\n","79 147 58 173\n","106  :  63.85281385281385\n","54 81 22 143\n","65 135 22 240\n","79 147 58 178\n","107  :  63.965884861407254\n","55 81 22 147\n","66 137 22 244\n","80 147 58 184\n","108  :  64.04255319148936\n","55 81 22 148\n","66 137 22 245\n","80 147 58 185\n","109  :  63.92405063291139\n","55 82 23 148\n","66 138 23 247\n","80 150 59 185\n","110  :  63.941299790356396\n","55 82 23 150\n","66 139 23 249\n","80 150 59 188\n","111  :  63.74999999999999\n","55 83 23 150\n","66 140 23 251\n","80 152 60 188\n","112  :  63.78600823045267\n","55 83 23 154\n","66 140 23 257\n","80 154 60 192\n","113  :  63.80368098159509\n","56 83 23 155\n","67 140 23 259\n","81 155 60 193\n","114  :  63.82113821138211\n","56 83 23 157\n","67 141 23 261\n","82 155 60 195\n","115  :  63.663967611336034\n","56 84 23 157\n","67 142 23 262\n","83 156 60 195\n","116  :  63.827655310621246\n","56 84 23 161\n","67 143 23 266\n","83 156 60 200\n","117  :  63.44621513944223\n","56 84 23 161\n","67 145 23 267\n","84 157 60 201\n","118  :  63.591269841269835\n","57 85 23 161\n","68 146 23 267\n","85 158 60 201\n","119  :  63.48425196850393\n","57 85 25 161\n","68 146 25 269\n","85 160 62 201\n","120  :  64.1891891891892\n","57 85 25 171\n","68 146 25 279\n","85 160 62 211\n","121  :  64.40839694656488\n","59 86 26 172\n","70 147 26 281\n","87 162 63 212\n","122  :  64.42125237191651\n","59 86 26 174\n","71 147 26 283\n","87 162 63 215\n","123  :  64.68926553672316\n","60 86 26 177\n","72 147 26 286\n","88 162 63 218\n","124  :  64.6455223880597\n","60 86 26 180\n","72 149 26 289\n","89 162 63 222\n","125  :  64.72222222222223\n","60 88 27 180\n","72 151 27 290\n","89 165 64 222\n","126  :  64.66789667896678\n","61 88 27 180\n","73 151 27 291\n","90 166 64 222\n","127  :  64.80804387568556\n","62 90 27 181\n","74 153 27 293\n","91 168 65 223\n","128  :  64.93624772313296\n","63 91 27 181\n","75 154 27 293\n","92 169 65 223\n","129  :  65.1978417266187\n","64 91 27 186\n","76 155 27 298\n","93 169 65 229\n","130  :  64.91071428571429\n","64 91 27 187\n","76 157 27 300\n","94 169 65 232\n","131  :  65.09769094138544\n","64 92 29 187\n","76 158 29 300\n","94 170 67 232\n","132  :  65.22887323943662\n","65 92 29 190\n","77 159 29 303\n","95 170 67 236\n","133  :  65.17543859649123\n","66 92 29 190\n","78 160 29 303\n","96 170 67 237\n","134  :  65.18324607329843\n","67 92 29 191\n","79 160 29 305\n","97 171 67 238\n","135  :  65.07798960138648\n","68 92 29 192\n","81 161 29 306\n","98 171 67 241\n","136  :  64.8881239242685\n","69 93 29 192\n","83 163 29 306\n","99 173 67 242\n","137  :  64.84641638225256\n","70 93 29 194\n","84 165 29 308\n","100 173 67 246\n","138  :  64.92411467116358\n","71 95 29 196\n","86 167 29 311\n","101 177 67 248\n","139  :  64.87394957983193\n","72 95 29 196\n","87 167 29 312\n","102 178 67 248\n","140  :  65.05823627287853\n","72 98 30 197\n","87 170 30 314\n","102 182 68 249\n","141  :  64.92537313432835\n","72 99 30 197\n","87 172 30 314\n","102 183 69 249\n","142  :  65.13157894736842\n","73 100 30 200\n","88 173 30 317\n","103 184 69 252\n","143  :  65.19607843137256\n","73 102 31 200\n","88 175 31 318\n","103 187 70 252\n","144  :  64.94345718901454\n","73 103 31 202\n","88 176 31 324\n","103 188 74 254\n","145  :  65.33546325878594\n","73 105 33 205\n","88 178 33 327\n","103 190 76 257\n","146  :  65.20700636942675\n","73 106 33 205\n","88 180 33 327\n","104 191 76 257\n","147  :  65.21394611727416\n","73 106 33 207\n","88 181 33 329\n","105 191 76 259\n","148  :  65.22082018927445\n","73 108 33 207\n","88 183 33 330\n","106 193 76 259\n","149  :  64.99215070643642\n","73 109 33 207\n","88 184 33 332\n","106 194 78 259\n","150  :  65.26479750778816\n","74 111 33 209\n","89 186 33 334\n","107 196 78 261\n","151  :  65.09287925696594\n","74 112 33 210\n","89 187 33 337\n","108 198 78 262\n","152  :  65.2073732718894\n","75 112 33 213\n","90 188 33 340\n","109 198 78 266\n","153  :  64.98470948012233\n","75 113 33 213\n","90 190 33 341\n","110 200 78 266\n","154  :  65.09146341463415\n","76 114 33 213\n","91 191 33 341\n","111 201 78 266\n","155  :  65.25679758308158\n","77 116 33 215\n","92 193 33 344\n","112 204 78 268\n","156  :  65.41353383458647\n","77 116 33 218\n","92 193 33 347\n","112 204 78 271\n","157  :  65.424739195231\n","78 116 33 221\n","93 195 33 350\n","113 204 78 276\n","158  :  65.03703703703704\n","78 116 33 221\n","93 195 33 354\n","113 204 82 276\n","159  :  64.77941176470588\n","79 117 33 221\n","94 197 33 356\n","114 207 82 277\n","160  :  65.28985507246377\n","79 117 33 231\n","94 197 33 366\n","114 207 82 287\n","161  :  65.44540229885058\n","79 119 34 233\n","94 199 34 369\n","114 210 83 289\n","162  :  65.74074074074075\n","80 119 34 238\n","95 199 34 374\n","115 210 83 294\n","163  :  65.88983050847457\n","80 119 34 243\n","95 200 34 379\n","115 210 83 300\n","164  :  65.82633053221288\n","80 120 36 244\n","95 201 37 381\n","115 213 85 301\n","165  :  65.92489568845619\n","81 122 36 245\n","97 203 37 382\n","116 215 85 303\n","166  :  66.20689655172414\n","82 124 38 246\n","98 205 39 383\n","117 217 87 304\n","167  :  66.07387140902873\n","83 125 38 247\n","100 206 39 386\n","118 220 88 305\n","168  :  66.12244897959184\n","84 127 38 247\n","101 208 39 387\n","119 223 88 305\n","169  :  66.12466124661248\n","84 128 38 248\n","101 209 39 389\n","120 224 88 306\n","170  :  66.08108108108108\n","85 128 38 248\n","102 210 39 389\n","121 224 88 307\n","171  :  66.44385026737967\n","85 130 38 254\n","102 212 39 395\n","121 226 88 313\n","172  :  66.53386454183267\n","86 131 38 256\n","104 213 39 397\n","122 228 88 315\n","173  :  66.31439894319684\n","86 131 39 256\n","104 213 40 400\n","122 231 89 315\n","174  :  66.49145860709592\n","87 133 39 257\n","105 215 40 401\n","123 233 89 316\n","175  :  66.62303664921467\n","88 135 39 257\n","106 217 40 401\n","124 235 89 316\n","176  :  66.62337662337663\n","89 137 39 258\n","108 219 40 403\n","126 238 89 317\n","177  :  66.70967741935485\n","89 139 40 259\n","108 221 41 405\n","126 241 90 318\n","178  :  66.87979539641944\n","90 139 40 264\n","109 222 41 410\n","127 241 90 324\n","179  :  66.83673469387756\n","91 139 40 264\n","110 223 41 410\n","128 241 90 325\n","180  :  66.70886075949367\n","92 141 40 264\n","112 225 41 412\n","129 246 90 325\n","181  :  66.5617128463476\n","92 142 40 265\n","112 227 41 414\n","129 248 91 326\n","182  :  66.3111668757842\n","92 142 40 265\n","113 229 41 414\n","129 248 94 326\n","183  :  66.47940074906367\n","93 144 41 265\n","114 231 42 414\n","130 250 95 326\n","184  :  66.52119700748129\n","93 144 41 266\n","114 231 42 415\n","130 250 95 327\n","185  :  66.27329192546584\n","93 144 41 266\n","114 233 42 416\n","130 250 98 327\n","186  :  66.44088669950739\n","94 146 41 269\n","115 235 43 419\n","131 252 98 331\n","187  :  66.48351648351648\n","95 149 41 270\n","116 239 43 421\n","132 256 99 332\n","188  :  66.28189550425273\n","95 149 41 271\n","116 241 43 423\n","133 256 99 335\n","189  :  66.60649819494586\n","95 149 41 279\n","116 241 43 431\n","133 256 99 343\n","190  :  66.40718562874251\n","95 149 41 280\n","116 243 43 433\n","133 257 101 344\n","191  :  66.44815256257449\n","95 150 41 282\n","116 244 43 436\n","133 259 101 346\n","192  :  66.41086186540733\n","95 150 41 287\n","116 246 43 442\n","134 259 101 353\n","193  :  66.4906103286385\n","96 150 41 290\n","117 247 43 445\n","135 259 101 357\n","194  :  66.53084982537834\n","96 150 41 295\n","117 248 43 451\n","135 260 101 363\n","195  :  66.53132250580046\n","97 150 41 296\n","118 249 43 452\n","136 260 101 365\n","196  :  66.60899653979239\n","97 153 41 297\n","118 252 43 454\n","136 263 102 366\n","197  :  66.26575028636884\n","97 153 41 298\n","118 252 43 460\n","137 267 102 367\n","198  :  66.45785876993166\n","97 155 42 300\n","118 254 44 462\n","137 269 103 369\n","199  :  66.68552036199095\n","98 157 42 303\n","119 256 44 465\n","138 271 103 372\n","200  :  66.83558558558559\n","98 159 42 305\n","119 258 44 467\n","138 273 103 374\n","201  :  66.72259507829978\n","99 160 42 306\n","120 259 44 471\n","140 276 103 375\n","202  :  66.79644048943271\n","100 162 42 307\n","121 261 44 473\n","141 279 103 376\n","203  :  66.61129568106313\n","100 163 42 307\n","121 263 44 475\n","142 281 104 376\n","204  :  66.72167216721672\n","100 163 42 312\n","121 264 44 480\n","142 281 104 382\n","205  :  66.64841182913473\n","101 164 42 312\n","122 266 44 481\n","143 283 105 382\n","206  :  66.72113289760348\n","102 164 42 315\n","123 267 44 484\n","144 283 105 386\n","207  :  66.79306608884073\n","103 166 42 316\n","124 269 44 486\n","145 286 105 387\n","208  :  66.63066954643628\n","103 167 42 316\n","124 270 44 488\n","145 288 106 387\n","209  :  66.77419354838709\n","104 169 43 316\n","125 272 45 488\n","146 290 107 387\n","210  :  66.91568836712914\n","104 169 43 322\n","125 272 45 495\n","146 291 107 393\n","211  :  67.16101694915254\n","105 169 43 328\n","126 272 45 501\n","147 291 107 399\n","212  :  67.33403582718651\n","106 169 43 332\n","127 272 45 505\n","148 291 107 403\n","213  :  67.33193277310924\n","106 170 44 332\n","127 273 46 506\n","148 293 108 403\n","214  :  67.39811912225704\n","107 172 44 333\n","128 275 47 507\n","149 295 108 405\n","215  :  67.34164070612668\n","107 173 47 333\n","128 276 50 509\n","149 296 113 405\n","216  :  67.33954451345755\n","108 173 47 334\n","129 277 50 510\n","150 296 113 407\n","217  :  67.06185567010309\n","108 173 47 334\n","129 277 50 514\n","151 299 113 407\n","218  :  67.1971252566735\n","109 173 47 337\n","130 277 50 517\n","152 299 113 410\n","219  :  67.2978505629478\n","109 173 49 338\n","130 277 52 518\n","152 299 115 411\n","220  :  67.31160896130346\n","110 174 49 340\n","132 278 52 520\n","153 301 115 413\n","221  :  67.3076923076923\n","111 175 49 342\n","133 279 52 524\n","154 304 115 415\n","222  :  67.33870967741935\n","111 175 50 344\n","133 279 53 527\n","154 305 116 417\n","223  :  67.10130391173522\n","111 176 50 344\n","133 280 53 531\n","155 309 116 417\n","224  :  66.89930209371884\n","111 176 50 346\n","134 280 53 536\n","157 310 116 420\n","225  :  66.86567164179105\n","111 177 50 346\n","134 282 53 536\n","157 311 117 420\n","226  :  66.83217477656405\n","112 177 50 346\n","135 282 53 537\n","158 312 117 420\n","227  :  66.76557863501483\n","112 178 50 347\n","135 284 53 539\n","158 314 118 421\n","228  :  66.61750245821042\n","113 179 50 348\n","136 286 53 542\n","160 316 118 423\n","229  :  66.58488714425907\n","113 180 50 348\n","136 288 53 542\n","161 317 118 423\n","230  :  66.53658536585367\n","114 182 50 349\n","138 290 53 544\n","162 321 118 424\n","231  :  66.60194174757281\n","115 183 50 351\n","139 291 53 547\n","163 323 118 426\n","232  :  66.68278529980658\n","115 184 52 352\n","139 292 55 548\n","163 324 120 427\n","233  :  66.50625601539943\n","116 185 52 352\n","140 294 55 550\n","164 327 120 428\n","234  :  66.18773946360153\n","116 185 52 352\n","140 295 55 554\n","165 330 120 429\n","235  :  66.22137404580153\n","117 185 52 354\n","141 296 55 556\n","166 330 120 432\n","236  :  66.22264509990485\n","117 186 53 354\n","141 297 56 557\n","166 332 121 432\n","237  :  66.22390891840607\n","117 186 53 356\n","141 298 56 559\n","167 332 121 434\n","238  :  66.41509433962264\n","118 186 53 361\n","142 298 56 564\n","168 332 121 439\n","239  :  66.32173095014112\n","118 187 53 361\n","142 299 56 566\n","168 334 122 439\n","240  :  66.35426429240863\n","118 187 53 364\n","142 300 56 569\n","168 334 122 443\n","241  :  66.4179104477612\n","119 189 53 365\n","143 302 56 571\n","169 337 122 444\n","242  :  66.48096564531104\n","120 191 53 366\n","145 304 56 572\n","170 339 122 446\n","243  :  66.54343807763401\n","121 191 53 369\n","146 305 56 575\n","171 339 122 450\n","244  :  66.60533578656855\n","121 192 53 372\n","146 307 56 578\n","172 340 122 453\n","245  :  66.60550458715596\n","122 193 53 372\n","147 308 56 579\n","173 342 122 453\n","246  :  66.43835616438356\n","123 194 53 372\n","148 310 56 581\n","174 345 123 453\n","247  :  66.40838650865997\n","124 194 53 372\n","149 310 56 582\n","175 346 123 453\n","248  :  66.289592760181\n","124 194 54 375\n","149 310 57 589\n","175 350 124 456\n","249  :  66.26126126126127\n","124 194 54 378\n","149 312 57 592\n","176 350 124 460\n","250  :  66.26344086021506\n","125 196 54 379\n","150 314 57 595\n","177 354 124 461\n","251  :  66.20535714285715\n","125 196 54 381\n","150 315 57 598\n","178 354 124 464\n","252  :  66.206589492431\n","125 197 55 381\n","150 316 58 599\n","179 355 125 464\n","253  :  66.0904255319149\n","126 197 55 382\n","151 318 58 601\n","180 355 128 465\n","254  :  66.18037135278514\n","127 198 56 382\n","152 319 59 601\n","181 356 129 465\n","255  :  66.30052724077329\n","128 198 56 387\n","153 320 59 606\n","182 356 129 471\n","256  :  66.19964973730298\n","129 199 56 387\n","154 322 59 607\n","183 358 129 472\n","257  :  66.17132867132867\n","130 199 56 387\n","155 323 59 607\n","184 358 129 473\n","258  :  66.23150565709312\n","130 201 56 389\n","155 325 59 610\n","184 360 130 475\n","259  :  66.26297577854672\n","131 201 56 393\n","156 327 59 614\n","185 360 130 481\n","260  :  66.20689655172414\n","132 201 56 394\n","157 329 59 615\n","186 360 130 484\n","261  :  66.20926243567753\n","133 202 56 396\n","158 331 59 618\n","187 362 130 487\n","262  :  66.08212147134303\n","133 203 56 396\n","158 333 59 619\n","188 364 130 487\n","263  :  66.22657580919932\n","134 203 56 400\n","159 333 59 623\n","189 364 130 491\n","264  :  66.2849872773537\n","134 205 58 400\n","159 335 61 624\n","189 367 132 491\n","265  :  66.42736486486487\n","135 207 58 402\n","160 337 61 626\n","190 369 132 493\n","266  :  66.59663865546219\n","135 207 58 408\n","160 337 61 632\n","190 369 132 499\n","267  :  66.62479061976549\n","135 209 59 408\n","160 339 62 633\n","190 372 133 499\n","268  :  66.68056713928273\n","136 210 60 409\n","162 340 63 634\n","191 374 134 500\n","269  :  66.68053244592346\n","136 211 60 410\n","162 341 63 636\n","192 375 134 501\n","270  :  66.59751037344398\n","137 211 60 410\n","163 341 63 638\n","193 377 134 501\n","271  :  66.58395368072787\n","137 212 60 412\n","163 342 63 641\n","194 378 134 503\n","272  :  66.58415841584159\n","137 212 62 412\n","163 342 65 642\n","194 379 136 503\n","273  :  66.44736842105263\n","137 213 62 412\n","163 343 65 645\n","194 381 138 503\n","274  :  66.52994257588188\n","138 215 62 412\n","164 345 65 645\n","195 383 138 503\n","275  :  66.53027823240589\n","138 215 62 414\n","164 346 65 647\n","196 383 138 505\n","276  :  66.55817737998373\n","139 215 62 418\n","165 348 65 651\n","197 383 138 511\n","277  :  66.61264181523501\n","139 215 62 422\n","165 349 65 655\n","198 383 138 515\n","278  :  66.66666666666666\n","140 216 62 422\n","166 350 65 655\n","199 384 138 515\n","279  :  66.72051696284329\n","140 217 63 422\n","166 351 66 655\n","199 385 139 515\n","280  :  66.80096696212732\n","141 219 63 422\n","167 353 66 655\n","200 387 139 515\n","281  :  66.90763052208835\n","141 221 64 423\n","167 355 67 656\n","200 389 140 516\n","282  :  66.90705128205127\n","142 222 64 423\n","168 357 67 656\n","201 390 140 517\n","283  :  66.8\n","142 222 64 423\n","168 357 67 658\n","201 391 141 517\n","284  :  66.85258964143426\n","143 222 64 426\n","169 358 67 661\n","202 391 141 521\n","285  :  66.93163751987281\n","144 224 64 426\n","170 360 67 661\n","203 393 141 521\n","286  :  67.0103092783505\n","145 226 64 426\n","171 362 67 661\n","204 395 141 521\n","287  :  67.03557312252964\n","146 226 64 428\n","172 362 67 664\n","205 396 141 523\n","288  :  67.08661417322834\n","146 227 67 428\n","172 363 70 665\n","205 397 145 523\n","289  :  67.11145996860283\n","146 228 69 428\n","172 364 72 666\n","205 399 147 523\n","290  :  67.0846394984326\n","146 229 69 428\n","172 366 72 666\n","205 400 148 523\n","291  :  67.34059097978226\n","146 229 69 438\n","172 366 72 676\n","205 400 148 533\n","292  :  67.41486068111455\n","146 231 69 441\n","172 368 72 680\n","205 403 148 536\n","293  :  67.2573189522342\n","146 233 69 441\n","172 370 72 684\n","205 405 152 536\n","294  :  67.19109746738296\n","147 234 69 442\n","173 373 72 685\n","206 406 152 539\n","295  :  67.26646248085758\n","148 236 69 442\n","174 375 72 685\n","207 408 152 539\n","296  :  67.3414820473644\n","148 238 70 442\n","174 377 73 685\n","207 410 153 539\n","297  :  67.33993902439023\n","149 238 70 443\n","175 378 73 686\n","208 410 153 541\n","298  :  67.41274658573596\n","150 240 70 445\n","176 380 73 689\n","209 412 154 543\n","299  :  67.51134644478064\n","150 242 72 445\n","176 382 75 689\n","209 414 156 543\n","300  :  67.50943396226415\n","151 242 72 446\n","178 382 75 690\n","210 414 156 545\n","301  :  67.55639097744361\n","152 244 72 447\n","179 384 75 692\n","211 417 156 546\n","302  :  67.65367316341829\n","153 246 72 448\n","180 386 75 693\n","212 419 156 547\n","303  :  67.65145848915482\n","154 246 72 449\n","181 387 75 694\n","213 419 156 549\n","304  :  67.72388059701493\n","155 248 72 449\n","182 389 75 694\n","214 421 156 549\n","305  :  67.62081784386616\n","155 249 73 449\n","183 391 76 695\n","214 424 157 550\n","306  :  67.62962962962963\n","155 250 73 452\n","183 393 76 698\n","215 425 157 553\n","307  :  67.64922623434046\n","156 250 73 456\n","184 395 76 702\n","216 425 157 559\n","308  :  67.70756796473182\n","156 251 74 458\n","184 396 77 704\n","216 426 158 561\n","309  :  67.77859237536657\n","156 252 74 460\n","184 397 77 706\n","216 427 158 563\n","310  :  67.79970760233918\n","156 254 75 460\n","184 399 78 707\n","216 430 159 563\n","311  :  68.03338171262699\n","156 254 75 470\n","184 399 78 717\n","216 430 159 573\n","312  :  68.02745664739885\n","156 254 76 473\n","185 399 79 721\n","216 431 160 577\n","313  :  68.09661139149243\n","156 256 77 473\n","185 401 80 721\n","216 433 161 577\n","314  :  68.0805176132279\n","157 258 77 473\n","186 403 80 722\n","217 436 161 577\n","315  :  68.0515759312321\n","158 258 78 474\n","187 405 81 723\n","218 436 162 580\n","316  :  67.94138670478912\n","158 259 78 474\n","187 407 81 724\n","219 438 162 580\n","317  :  67.93865905848787\n","159 259 78 475\n","188 407 81 726\n","220 439 162 581\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-ce5e2c1f41e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_te\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m           \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0;31m#print(\"{:15} {:5}: ({})\".format(\"Word\", \"Pred\", \"True\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     def train_on_batch(self, x, y,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: len(seq_lens) != input.dims(0), (25 vs. 24)\n\t [[{{node lambda_5/module_4_apply_tokens/bilm/ReverseSequence}}]]"]}]}]}